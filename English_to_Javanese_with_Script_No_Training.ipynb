{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f83ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "from IPython.display import display, Markdown\n",
    "from ipywidgets import widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "import requests\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from transformers import AdamW, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aba70b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_repo = 'google/mt5-small'\n",
    "model_path = './mt5_translation_small.pt'\n",
    "max_sequence_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f924e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c4f686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_repo)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1f12d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_mapping = {\n",
    "    'en': '<en>',\n",
    "    'jv': '<jv>'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f257241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(250102, 768)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens_dict = {'additional_special_tokens': list(languages_mapping.values())}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4455cb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_input_str(text, target_language, tokenizer, sequence_length, lang_mapping=languages_mapping):\n",
    "    target_lang_token = lang_mapping[target_language]\n",
    "\n",
    "    # tokenize\n",
    "    input_ids = tokenizer.encode(\n",
    "      text = target_lang_token + text,\n",
    "      return_tensors = 'pt',\n",
    "      padding = 'max_length',\n",
    "      truncation = True, # max 20 sequence, model limitation\n",
    "      max_length = sequence_length\n",
    "    )\n",
    "\n",
    "    return input_ids[0]\n",
    "\n",
    "def encode_target_str(text, tokenizer, sequence_length):\n",
    "    token_ids = tokenizer.encode(\n",
    "      text = text,\n",
    "      return_tensors = 'pt',\n",
    "      padding = 'max_length',\n",
    "      truncation = True, # max 20 sequence, model limitation\n",
    "      max_length = sequence_length\n",
    "    )\n",
    "\n",
    "    return token_ids[0]\n",
    "\n",
    "def format_translation_data(translations, tokenizer, sequence_length, lang_mapping=languages_mapping):\n",
    "    # Choose randomly between en or jv as input and target languages\n",
    "    languages = list(lang_mapping.keys())\n",
    "    input_language, target_language = np.random.choice(languages, size=2, replace=False)\n",
    "\n",
    "    # Get translations for the batch\n",
    "    input_text = translations[input_language]\n",
    "    target_text = translations[target_language]\n",
    "\n",
    "    if input_text is None or target_text is None: \n",
    "        return None\n",
    "\n",
    "    input_token_ids = encode_input_str(\n",
    "    input_text, target_language, tokenizer, sequence_length)\n",
    "\n",
    "    target_token_ids = encode_target_str(\n",
    "    target_text, tokenizer, sequence_length)\n",
    "\n",
    "    return input_token_ids, target_token_ids\n",
    "\n",
    "def transform_batch(batch, tokenizer):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for translations_set in batch['translation']:\n",
    "        formatted_data = format_translation_data(translations_set, tokenizer, max_sequence_length)\n",
    "\n",
    "        if formatted_data is None: \n",
    "            continue\n",
    "\n",
    "        input_lang_ids, target_lang_ids = formatted_data\n",
    "        inputs.append(input_lang_ids.unsqueeze(0))\n",
    "        targets.append(target_lang_ids.unsqueeze(0))\n",
    "        # print(input_lang_ids)\n",
    "        # print(target_lang_ids)\n",
    "        # break\n",
    "\n",
    "    batch_input_ids = torch.cat(inputs).cuda()\n",
    "    batch_target_ids = torch.cat(targets).cuda()\n",
    "\n",
    "    return batch_input_ids, batch_target_ids\n",
    "\n",
    "def get_data_generator(dataset, tokenizer, batch_size=32):\n",
    "    dataset = dataset.sample(frac=1)\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        raw_batch = dataset[i:i+batch_size]\n",
    "        yield transform_batch(raw_batch, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eacee9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "499e9114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw input text: What are you thinking about so early in the morning?\n",
      "Truncated input: <jv> What are you thinking about so early in the morning?</s><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "test_sentence = 'What are you thinking about so early in the morning?'\n",
    "print('Raw input text:', test_sentence)\n",
    "\n",
    "input_ids = encode_input_str(\n",
    "    text = test_sentence,\n",
    "    target_language='jv',\n",
    "    tokenizer=tokenizer,\n",
    "    sequence_length=model.config.max_length,\n",
    "    lang_mapping=languages_mapping,\n",
    ")\n",
    "input_ids = input_ids.unsqueeze(0).cuda()\n",
    "\n",
    "print('Truncated input:', tokenizer.convert_tokens_to_string(\n",
    "    tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5636c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apa sing dadi impenmu ing wayah bangun esuk?\n",
      "Apa sing dadi impenmu esuk umun-umun awan?\n",
      "Apa sing dadi impenmu ing wayah bangun esuk, kuwi \n",
      "Apa sing dadi impenmu ing wayah bangun esuk melek?\n",
      "Apa sing dadi impenmu ing wayah esuk melek?\n",
      "Apa sing dadi impenmu ing wayah esuk, esuke-e\n",
      "Apa sing dadi impenmu ing wayah bangun esuk, awan \n",
      "Apa sing dadi impenmu ing wayah esuk?\n",
      "Apa sing dadi impenmu ing wayah bangun esuk melek melek\n",
      "Apa sing dadi impenmu ing wayah esuk, awan awan apa\n"
     ]
    }
   ],
   "source": [
    "output_tokens = model.generate(input_ids, num_beams=10, num_return_sequences=10)\n",
    "for token_set in output_tokens:\n",
    "    print(tokenizer.decode(token_set, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86427ef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## English: \n",
       " ### What are you thinking about so early in the morning?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Javanese: \n",
       " ### Apa sing dadi impenmu ing wayah bangun esuk?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       " ## Javanese script: \n",
       " ## ꧋ꦲꦥꦱꦶꦁꦢꦢꦶꦲꦶꦩ꧀ꦥꦺꦤ꧀ꦩꦸꦲꦶꦁꦮꦪꦃꦧꦔꦸꦤ꧀ꦲꦺꦱꦸꦏ꧀?\n",
       " ‎"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoded_first_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "url = 'https://latin-java.vercel.app/api/get_javanese_script'\n",
    "latin_text = {'latin_text': decoded_first_text}\n",
    "x = requests.post(url, json = latin_text)\n",
    "\n",
    "display(Markdown(f\"## English: \\n ### {test_sentence}\"))\n",
    "display(Markdown(f\"## Javanese: \\n ### {tokenizer.decode(output_tokens[0], skip_special_tokens=True)}\"))\n",
    "display(Markdown(f\"\\n ## Javanese script: \\n ## {eval(x.text)['javanese_script']}\\n ‎\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
